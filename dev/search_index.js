var documenterSearchIndex = {"docs":
[{"location":"api/#API-for-MaximumWeightTwoStageSpanningTree.jl","page":"API reference","title":"API for MaximumWeightTwoStageSpanningTree.jl","text":"","category":"section"},{"location":"api/#Public","page":"API reference","title":"Public","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"Modules = [MaximumWeightTwoStageSpanningTree]\nPrivate = false","category":"page"},{"location":"api/#MaximumWeightTwoStageSpanningTree.benders-Tuple{MaximumWeightTwoStageSpanningTree.TwoStageSpanningTreeInstance}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.benders","text":"function two_stage_spanning_tree_benders(inst::TwoStageSpanningTreeInstance;MILP_solver=GLPK.Optimizer, tol=0.000001)\n\ncomputes an optimal solution (with tolerance tol) of the two stage spanning tree problem using a Benders approach.\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.build_or_load_spanning_tree_CO_layer_datasets-Tuple{}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.build_or_load_spanning_tree_CO_layer_datasets","text":"function buildorloadspanningtreeCOlayerdatasets(     ;     onlysmall=false,      parallel=false,     normalized=true     # To get normalized features )\n\nReturns three dictionnaries: trainingdatasets, validationdatasets, testdatasets Each entry of each dictionnary is of the forme datasetname, dataset\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.build_solve_and_encode_instance_as_maximum_weight_spanning_tree_single_scenario_layer-Tuple{}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.build_solve_and_encode_instance_as_maximum_weight_spanning_tree_single_scenario_layer","text":"function build_solve_and_encode_instance_as_maximum_weight_spanning_tree_single_scenario_layer(;\n    grid_size=3,\n    seed=0,\n    nb_scenarios=10, \n    first_max=10, \n    second_max=20, \n    solver=lagrangian_heuristic_solver, \n    load_and_save=true\n)\n\nBuilds a two stage spanning tree instance with a square grid graph of width grid_size, seed for the random number generator, nb_scenarios for the second stage, first_max and second_max as first and second stage maximum weight.\n\nSolves it with solver\n\nEncodes it for a pipeline with a maxium weight spanning tree for a two stage instance with single scenario second stage layer.\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.column_generation-Tuple{MaximumWeightTwoStageSpanningTree.TwoStageSpanningTreeInstance}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.column_generation","text":"function column_generation_two_stage_spanning_tree(inst::TwoStageSpanningTreeInstance;MILP_solver=GLPK.Optimizer,tol=0.00001)\n\nSolves the dual of the linear relaxation of the two stage spanning tree MILP using a constraint generation.\n\nreturns objective_value, duals\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.cut_generation-Tuple{MaximumWeightTwoStageSpanningTree.TwoStageSpanningTreeInstance}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.cut_generation","text":"function two_stage_spanning_tree_cut_generation(inst::TwoStageSpanningTreeInstance;MILP_solver=GLPK.Optimizer, separate_constraint_function=separate_forest_polytope_constraint_vertex_set_using_min_cut_MILP_formulation!, tol=0.000001, silent=false)\n\nSolve the TwoStageSpanningTree instance inst using a cut generation approach.\n\nseparate_constraint_function indicates which method is used to separate the constraint on subsets of vertices. One option is available\n\nseparate_forest_polytope_constraint_vertex_set_using_min_cut_MILP_formulation!\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.evaluate_first_stage_solution-Tuple{MaximumWeightTwoStageSpanningTree.TwoStageSpanningTreeInstance, Any}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.evaluate_first_stage_solution","text":"function evaluate_two_stage_spanning_tree_first_stage_solution(inst::TwoStageSpanningTreeInstance, forest)\n\nreturns the value of the solution of inst with forest as first stage solution. \n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.lagrangian_relaxation-Tuple{MaximumWeightTwoStageSpanningTree.TwoStageSpanningTreeInstance}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.lagrangian_relaxation","text":"function lagrangian_relaxation(inst::TwoStageSpanningTreeInstance; nb_epochs=100)\n\nruns\n - a subgradient algorithm during nb_epochs to solve the Lagrangian relaxation of inst (with `θ` initialized to 0)\n - a lagrangian heuristic on the resulting solution\n\nreturns lb , ub, forest, θ, training_losses with\n- lb: value of the Lagrangian relaxation\n- ub: value of the solution computed by the lagrangian heuristic\n- forest: solution computed by the lagrangian heuristic\n- θ: second stage problem value\n- training_losses: vector with the value of the training losses along the subgradient algorithm\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.maximum_weight_spanning_tree_single_scenario_linear_maximizer-Tuple{AbstractMatrix}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.maximum_weight_spanning_tree_single_scenario_linear_maximizer","text":"function maximum_weight_spanning_tree_single_scenario_linear_maximizer(θ::AbstractMatrix;inst=inst)\n\nWrapper around kruskalmaximumweightspanningtreesinglescenario(edgeweightsvector::AbstractVector, inst::TwoStageSpanningTreeInstance) that returns the solution encoded as a vector.\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.test_models_on_data_set-Tuple{}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.test_models_on_data_set","text":"function testmodelsondataset(     ;     models,    # Model name     dataset,   # Dataset obtained with build_or_load_spanning_tree_CO_layer_datasets()   )\n\nreturns an array, each instance of which contains a tuple (inst, lb, UBs) where\n\ninst is an instance \nlb is the lower bound (lagrangian or optimal solution) \nUbs  is a dictionnary with the ub (lagrangian or exaxt), and the performance of every model on the instance\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.test_or_load_models_on_datasets-Tuple{}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.test_or_load_models_on_datasets","text":"function testorloadmodelsondatasets(;models, datasets, resultsfolder,recompute_results=false)\n\nreturns a dict with the results of all the models on each dataset. Results are saved. If results file exists, loads it except if recompute_results=true\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.train_bbl_model_and_add_to_dict!-Tuple{Any}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.train_bbl_model_and_add_to_dict!","text":"function trainbblmodelandaddtodict!(     models                      # Dictionnary to which the result will be added     ;     traindataname,            # Data name (to save on disk)     traindata,                 # Data obtained with `buildorloadspanningtreeCOlayerdatasets()`     nbDIRECTiterations=1000,  # Nb iterations of the black box algorithm (DIRECT)     perturbed=false,            # Activate Gaussian perturbation     nbperturbations=20,        # Nb pertubation scenarios     perturbationintensity=0.1, # Strength of the pertubation     force_recompute=false       # learn even if model available on disk )\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.train_save_or_load_FYL_model!-Tuple{}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.train_save_or_load_FYL_model!","text":"function trainsaveorloadFYLmodel!(     ;     nbsamples,         # nbsamples used in FYL perturbation     traindataname,    # name of the training set (used for saving or loading)     traindata,         # dataset of instance obtained with build_or_load_spanning_tree_CO_layer_datasets()     nbepochs           # nbepochs in the stochastic gradient descent )\n\n\n\n\n\n","category":"method"},{"location":"api/#Private","page":"API reference","title":"Private","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"Modules = [MaximumWeightTwoStageSpanningTree]\nPublic= false","category":"page"},{"location":"api/#MaximumWeightTwoStageSpanningTree.BlackBoxLoss","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.BlackBoxLoss","text":"struct BlackBoxLoss{A<:AbstractArray,I,P} <: Function\n    nb_features::Int\n    nb_samples::Int\n    training_set::Vector{Tuple{A,I,Float64}}\n    cost_pipeline::P     # Cost ∘ Decoder ∘ Maximizer: Outputs a solution\nend\n\nEncodes all the information for learning a problem by experience.\n\n\n\n\n\n","category":"type"},{"location":"api/#MaximumWeightTwoStageSpanningTree.BlackBoxLoss-NTuple{4, Any}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.BlackBoxLoss","text":"function BlackBoxLoss(training_data,maximizer,decoder,cost_function;scaling_function=x->1.0)\n\nConstructor for a BlackBoxLoss\n\nPipeline: x –GLM–> θ –Maximizer–> y –Decoder–> z\n\ntraining_data: Vector(x,inst) where inst is an instance of the problem and x its features encoding\nmaximizer(θ,inst)\ndecoder(y,inst)\ncost_function(z,inst)\nscaling_function: order of magnitude of cost_function(z_optimal,inst):\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.CountFunctionCall","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.CountFunctionCall","text":"mutable struct CountFunctionCall{F}     counter::Int     const f::F end\n\nWrapper around a function to print the number of call to the function\n\n\n\n\n\n","category":"type"},{"location":"api/#MaximumWeightTwoStageSpanningTree.CountFunctionCall-Tuple{Any}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.CountFunctionCall","text":"Wrapper around a function to print the number of call to the function\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.TwoStageSpanningTreeInstance","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.TwoStageSpanningTreeInstance","text":"TwoStageSpanningTreeInstance\n\nContains all the relevant information defining a two stage spanning-tree instance\n\nFields\n\ng::SimpleGraph{Int}: Graph\nedge_index::SparseMatrixCSC{Int64, Int64}: edge_index[src(e),dst(e)] contains the Int index of edge e\nnb_scenarios::Int:\nfirst_stage_weights_matrix::SparseMatrixCSC{Float64, Int64}:\nfirst_stage_weights_vector::Vector{Float64}:\nsecond_stage_weights::Vector{SparseMatrixCSC{Float64, Int64}}:\n\n\n\n\n\n","category":"type"},{"location":"api/#MaximumWeightTwoStageSpanningTree.TwoStageSpanningTreeInstance-Tuple{Graphs.AbstractGraph}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.TwoStageSpanningTreeInstance","text":"function TwoStageSpanningTreeInstance(g::AbstractGraph;nb_scenarios=1, first_max=10, second_max=20, negative_weights=false)\n\nConstructor of TwoStageSpanningTreeInstance\n\ng::AbstractGraph is the graph\nfirst stage costs are randomly chosen between 1 and first_max\nsecond stage costs are randomly chosen between 1 and second_max\nweights are negative is negative_weights is true (multiplies weights above by -1)\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.black_box_loss-Tuple{AbstractVector, MaximumWeightTwoStageSpanningTree.BlackBoxLoss}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.black_box_loss","text":"function black_box_loss(w::AbstractVector,bbl::BlackBoxLoss)\n\nEvaluates BlackBoxLoss when its GLM parameters are given by w\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.build_dataset-Tuple{}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.build_dataset","text":"function builddataset(;     nbscenarios=5:5:20,     firstmax=20:20,     secondmax=10:5:30,     seeds=1:5,     gridsizes=4:6,     solver=benderssolver, )\n\nBuild a training/valisation/test dataset for two stage spanning tree pipelines with a minimum weight spanning tree CO layer\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.build_flow_graph_for_constraint_pricing!","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.build_flow_graph_for_constraint_pricing!","text":"function build_flow_graph_for_constraint_pricing!(\n    g::MetaGraph,\n    flow_graph::MetaDiGraph,\n    base_graph_vertices_vertex_index_in_flow_graph = Dict(),\n    base_graph_edges_vertex_index_in_flow_graph = Dict()\n)\n\nConstraint separated: ∑{e in E(X)}xe <= |X| - 1 for any ∅ ⊊ X ⊊ V`\n\ng is the undirected graph on which the forest polytope is manipulated.\nflow_graph is a MetaDiGraph. It should be empty in input. It is modified by the function and contains afterwards the MetaDiGraph used to separate the forest polytope constraint on f\n\n\n\n\n\n","category":"function"},{"location":"api/#MaximumWeightTwoStageSpanningTree.build_load_or_solve-Tuple{}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.build_load_or_solve","text":"function build_load_or_solve(;\n    graph=grid(5,5),\n    seed=0,\n    nb_scenarios=10,\n    first_max=10,\n    second_max=20,\n    solver=lagrangian_heuristic_solver,\n    load_and_save=true\n)\n\nThree solvers available\n\n- `cut_solver`\n- `benders_solver`\n- `lagrangian_heuristic_solver`\n\nreturn inst, val, sol with\n\n- `inst`: the instance generated\n- `val`: value of the solution computed\n- `solution_computed`: solution computed\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.compute_σ-Tuple{Any}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.compute_σ","text":"function compute_σ(X)\n\nComputes features standard deviation\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.edge_index-Tuple{MaximumWeightTwoStageSpanningTree.TwoStageSpanningTreeInstance, Graphs.AbstractEdge}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.edge_index","text":"function edge_index(inst::TwoStageSpanningTreeInstance,e::AbstractEdge) \n    \nreturns inst.edge_index[src(e),dst(e)]\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.evaluate_two_stage_spanning_tree_first_stage_solution_and_compute_second_stage-Tuple{MaximumWeightTwoStageSpanningTree.TwoStageSpanningTreeInstance, Any}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.evaluate_two_stage_spanning_tree_first_stage_solution_and_compute_second_stage","text":"function evaluate_two_stage_spanning_tree_first_stage_solution(inst::TwoStageSpanningTreeInstance, forest)\n\nreturns (val, secondstagessol) the value of the solution of inst with forest as first stage solution. \n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.kruskal_mst_value","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.kruskal_mst_value","text":"kruskal_mst_value(g, distmx=weights(g); minimize=true)\n\nextends kruskal_mst to return also the mst value\n\nreturns (mst weight), (mst edges)\n\n\n\n\n\n","category":"function"},{"location":"api/#MaximumWeightTwoStageSpanningTree.kruskal_on_first_scenario_instance-Tuple{MaximumWeightTwoStageSpanningTree.TwoStageSpanningTreeInstance}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.kruskal_on_first_scenario_instance","text":"kruskalonfirstscenarioinstance(instance::TwoStageSpanningTreeInstance)\n\napplies Kruskal algorithm with weight inst.first_stage_weights + inst.second_stage_weights[1]\n\nreturn value, first_stage_value, first_stage_solution\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.lagrangian_dual-Tuple{AbstractArray}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.lagrangian_dual","text":"lagrangian_dual(θ::AbstractArray; inst::TwoStageSpanningTreeInstance)\n\ncomputes the value of the lagrangian dual function for TwoStageSpanningTreeInstance instance inst with duals θ\n\nθ[edged_index(src(e),dst(e)),s] contains the value of the Lagrangian dual corresponding to edge e for scenario s\n\nChainRulesCore.rrule automatic differentiation with respect to θ works.\n\nreturn (value of the solution computed),(edges in the solution computed)\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.lagrangian_dual_stochastic-Tuple{AbstractArray}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.lagrangian_dual_stochastic","text":"lagrangian_dual(θ::AbstractArray; inst::TwoStageSpanningTreeInstance)\n\ncomputes a stochastique (for one random scenario) value of the lagrangian dual function for TwoStageSpanningTreeInstance instance inst with duals θ\n\nθ[edged_index(src(e),dst(e)),s] contains the value of the Lagrangian dual corresponding to edge e for scenario s\n\nChainRulesCore.rrule automatic differentiation with respect to θ works (and returns a stochastix gradient of the lagrangian dual function)\n\nreturn (value of the solution computed),(edges in the solution computed)\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.lagrangian_heuristic-Tuple{AbstractArray}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.lagrangian_heuristic","text":"function lagrangian_heuristic(θ::AbstractArray; inst::TwoStageSpanningTreeInstance)\n\nperforms a lagrangian heuristic on TwoStageSpanningTree instance inst with duals θ.\n\nθ[edge_index(src(e),dst(e)),s] contains the value of the Lagrangian dual corresponding to edge e for scenario s\n\nreturn (value of the solution computed),(edges in the solution computed)\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.maximum_weight_spanning_tree_single_scenario_layer_linear_encoder-Tuple{MaximumWeightTwoStageSpanningTree.TwoStageSpanningTreeInstance}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.maximum_weight_spanning_tree_single_scenario_layer_linear_encoder","text":"function maximum_weight_spanning_tree_single_scenario_layer_linear_encoder(inst::TwoStageSpanningTreeInstance)\n    (inst::TwoStageSpanningTreeInstance)\n\nreturns X::Array{Float64} with `X[f,edge_index(inst,e),s]` containing the value of feature number `f` for edge `e` and scenario `s`\n\nFeatures used: (all are homogeneous to a cost)\n- first_stage_cost \n- second_stage_cost_quantile\n- neighbors_first_stage_cost_quantile \n- neighbors_scenario_second_stage_cost_quantile \n- is_in_first_stage_x_first_stage_cost \n- is_in_second_stage_x_second_stage_cost_quantile \n- is_first_in_best_stage_x_best_stage_cost_quantile \n- is_second_in_best_stage_x_best_stage_cost_quantile \n\nFor features with quantiles, the following quantiles are used: 0:0.1:1\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.reduce_data!-Tuple{Any, Any}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.reduce_data!","text":"function reduce_data!(X, σ)\n\nStandarizes features without centering them\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.separate_forest_polytope_constraint_vertex_set_using_min_cut_MILP_formulation!-Tuple{MetaGraphs.MetaGraph}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.separate_forest_polytope_constraint_vertex_set_using_min_cut_MILP_formulation!","text":"separate_forest_polytope_constraint_vertex_set_using_min_cut_MILP_formulation!(g::MetaGraph; MILP_solver=GLPK.Optimizer)\n\nUses a simple MILP to separate the constraints Constraint separated: ∑{e in E(X)} xe <= |X| - 1 for any ∅ ⊊ X ⊊ V`\n\ng is a MetaGraph, :cb_val property contains the value of x_e\n\nreturns: found, X\n\nfound : boolean indicating if a violated constraint has been found\nX : vertex set corresponding to the violated constraint\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.separate_mst_Benders_cut!-Tuple{MetaGraphs.MetaGraph}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.separate_mst_Benders_cut!","text":"separate_mst_Benders_cut!(g::MetaGraph ; MILP_solver=GLPK.Optimizer)\n\nseparates optimality and feasibility cuts for the Benders decomposition formulation of the MST problem\n\ninput: property :x_val contains the value of the master property :weight contains the value of the second stage\n\nreturns a boolean equals to true if the cut is a feasibility cut and false if it is an optimality cut (in that case, the cut might be satisfied)\n\nThe value of the duals μ and ν are stored in properties :mu and :nu of the g\n\n\n\n\n\n","category":"method"},{"location":"api/#MaximumWeightTwoStageSpanningTree.train_save_load_BBL_model-Tuple{}","page":"API reference","title":"MaximumWeightTwoStageSpanningTree.train_save_load_BBL_model","text":"function trainsaveloadBBLmodel(     ;     traindataname,            # Data name (to save on disk)     traindata,                 # Data obtained with `buildorloadspanningtreeCOlayerdatasets()`     nbDIRECTiterations=1000,  # Nb iterations of the black box algorithm (DIRECT)     perturbed=false,            # Activate Gaussian perturbation     nbperturbations=20,        # Nb pertubation scenarios     perturbationintensity=0.1, # Strength of the pertubation     force_recompute=false       # learn even if model available on disk )\n\n\n\n\n\n","category":"method"},{"location":"api/#Index","page":"API reference","title":"Index","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"","category":"page"},{"location":"optimization/#Spanning-tree-polytope-and-branch-and-cut-formulation","page":"Optimization algorithms","title":"Spanning tree polytope and branch and cut formulation","text":"","category":"section"},{"location":"optimization/#Spanning-tree-polytope","page":"Optimization algorithms","title":"Spanning tree polytope","text":"","category":"section"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"The spanning tree polytope mathcalP","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    beginarrayll\n        sum_e in E x_e = V-1 \n        sum_e in E(X) x_e leq X - 1 qquad textfor all  emptyset subsetneq X subsetneq V\n    endarray","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"The forest polytope is obtained when we remove the first constraint.","category":"page"},{"location":"optimization/#Min-cut-MILP-for-the-separation-problem","page":"Optimization algorithms","title":"Min cut MILP for the separation problem","text":"","category":"section"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"The separation problem ","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    min  X - 1 - sum_e in E(X) x_e quad textsubject to quad emptyset subsetneq X subsetneq V","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"is equivalent to","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    min  X + sum_e notin E(X) x_e - V quad textsubject to quad emptyset subsetneq X subsetneq V","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"Let us define the digraph mathcalD = (mathcalVmathcalA) with vertex set mathcalV = st cup V cup E and the following arcs.","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"Arc a Capacity u_a\n(se) for e in E x_e\n(eu) and (ev) for e = (uv) in E infty\n(vt) for v in V 1","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"The separation problem is equivalent to finding a non-empty minimum a minimum-capacity s-t cut X in mathcalD. This can be done with the following MILP.","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    beginarrayrll\n        min   sum_a in mathcalA u_a z_a \n        mathrmst   y_s - y_t geq 1 \n         z_a geq y_u - y_v  text for all  a= (uv) in mathcalA \n         sum_v in V y_v geq 1 \n         yz in 01 \n    endarray","category":"page"},{"location":"optimization/#Branch-and-cut-formulation-for-the-minimum-spanning-tree-problem","page":"Optimization algorithms","title":"Branch and cut formulation for the minimum spanning tree problem","text":"","category":"section"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"Using the spanning tree polytope, we can reformulate the minimum spanning tree problem as","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    beginarrayrll\n        min displaystylesum_e in Ec_e x_e \n        mathrmstdisplaystylesum_e in E x_e = V-1 \n        displaystylesum_e in E(X) x_e leq X - 1 qquad textfor all  emptyset subsetneq X subsetneq V\n    endarray","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"A callback based version of the Branch-and-Cut algorithm is implemented in the function minimum_spanning_tree_MILP!. Its keyword argument separate_constraint_function enables to select the optimization algorithm used to separate constraints:","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"separate_forest_polytope_constraint_vertex_set_using_min_cut_MILP_formulation! uses the cut-based formulation.","category":"page"},{"location":"optimization/#Branch-and-cut-formulation-for-the-two-stage-minimum-spanning-tree-problem","page":"Optimization algorithms","title":"Branch and cut formulation for the two stage minimum spanning tree problem","text":"","category":"section"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"In the same vein, we can propose the following formulation of the two stage spanning tree problem","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    beginarrayrll\n        min displaystylesum_e in Ec_e x_e + frac1Ssum_e in Esum_s in Sd_esy_es\n        mathrmstdisplaystylesum_e in E x_e + y_es = V-1  textfor all s in S \n        displaystylesum_e in E(X) x_e + y_es leq X - 1 qquad textfor all  emptyset subsetneq X subsetneq E text and  s in S \n         xy in 01\n    endarray","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"Again, the keyword argument separate_constraint_function enables to select the optimization algorithm used to separate constraints among the two mentioned above.","category":"page"},{"location":"optimization/#Column-generation-formulation","page":"Optimization algorithms","title":"Column generation formulation","text":"","category":"section"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"The cut generation previously mentioned is quite slow.  Since minimum spanning tree can be solved efficiently, it is natural to perform and Dantzig-Wolfe reformulation of the problem previously introduced.","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"It leads to the following formulation.","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    beginarrayrll\n        min displaystylesum_e in Ec_e x_e +  frac1Ssum_e in Esum_s in Sd_esy_es\n        mathrmst  x_e + y_es = displaystylesum_T in mathcalTcolon e in T lambda_Ts  textfor all ein E and s in S \n         displaystylesum_T in mathcalT lambda_Ts = 1  textfor all s in S \n         xyin mathbbZ_+ \n        lambda geq 0\n    endarray","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"The linear relaxation of this problem can be solved by column generation, and the problem itself can be solved using a Branch-and-Price.  The column generation is implemented in the function column_generation_two_stage_spanning_tree. Practically, we have coded directly the constraint generation on the dual using a callback mechanism.","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"To avoid the Branch-and-Price, we instead use a Benders decomposition of this problem, which enables to rely on the callback-mechanism of the solve, and avoid coding the branching scheme.","category":"page"},{"location":"optimization/#Benders-decomposition","page":"Optimization algorithms","title":"Benders decomposition","text":"","category":"section"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"Let us now perform a Benders decomposition of the column generation formulation provided above.","category":"page"},{"location":"optimization/#Dual-of-the-second-stage-problem","page":"Optimization algorithms","title":"Dual of the second stage problem","text":"","category":"section"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"If we fix x, the second stage problem for scenario s becomes","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    beginarrayrll\n        min_ylambda displaystyle frac1Ssum_e in Ed_esy_es\n        mathrmst  y_es = displaystylesum_T in mathcalTcolon e in T lambda_Ts - x_e   textfor all ein E  \n         displaystylesum_T in mathcalT lambda_Ts = 1 \n         y geq 0\n        lambda geq 0\n    endarray","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"We have dropped the integrality constraint on y since the spanning tree polytope is integral.  Let us drop the frac1S, and remove the variables y disappear to obtain the equivalent LP","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    beginarrayrlll\n        min_lambda displaystyle sum_T in mathcalTlambda_T d_Ts - overbracesum_sd_esx_es^textconstant\n        mathrmst  displaystylesum_T in mathcalTcolon e in T lambda_Ts geq x_e    textfor all ein E  text(dual mu_es) \n         displaystylesum_T in mathcalT lambda_Ts = 1    text(dual nu_s) \n        lambda geq 0\n    endarray","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"where d_Ts = sum_e in Td_es. Taking its dual, we get","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    beginarrayrlll\n        max_munu displaystyle nu_s + sum_emu_esx_e - overbracesum_sd_esx_es^textconstant\n        mathrmst  d_Rs - nu_s - sum_e in T mu_es geq 0  textfor all T in mathcalT\n        mu geq 0\n    endarray","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"which we can solve using a constraint generation.","category":"page"},{"location":"optimization/#Cut-generation-algorithm","page":"Optimization algorithms","title":"Cut generation algorithm","text":"","category":"section"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"The separation problem for the dual above is ","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    min_T in mathcalT sum_e in T d_es - mu_es","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"where we have replaced d_Ts by its value. It is a minimum spanning tree problem and can be solved using Kruskal's algorithm.","category":"page"},{"location":"optimization/#Feasibility-and-optimality-cuts","page":"Optimization algorithms","title":"Feasibility and optimality cuts","text":"","category":"section"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"If the primal admits a solution, an optimal solution nu_smu_es of the dual problem provides an optimality cut","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    theta_s geq nu_s + sum_emu_esx_e - sum_sd_esx_es","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"If the primal problem is not feasible, the solver is supposes to return an unbounded ray for the dual, that is, a solution munu such that","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    beginarrayll\n        nu_s + sum_emu_esx_e  0 \n        -nu_s - sum_e in T mu_es geq 0  textfor all T in mathcalT\n    endarray","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"Such an unbounded ray leads to a feasibility cut","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    nu + sum_emu_ex_e leq 0","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"where we intentionally drop the scenario subscript since these feasibility cuts are not scenario dependent. Practically, since solvers do not always provide extreme-rays, probably due to identification of unfeasibility at presolve, we consider the following simplex initialization of the primal","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    beginarrayrlll\n        min_lambdax displaystyle sum_e in Ew_e\n        mathrmst  displaystylesum_T in mathcalTcolon e in T lambda_Ts + w_e geq x_e    textfor all ein E  text(dual mu_es) \n         displaystylesum_T in mathcalT lambda_Ts = 1    text(dual nu_s) \n        lambdaw geq 0\n    endarray","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"where we have added the slack variables w. Taking its dual, we get","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    beginarrayrlll\n        max_munu displaystyle nu_s + sum_emu_esx_e \n        mathrmst  - nu_s - sum_e in T mu_es geq 0  textfor all T in mathcalT\n         0 leq mu leq 1 \n         nu leq 1\n    endarray","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"which we can solve using a similar constraint generation.","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"Practically, we start with a constraint generation on the feasibility cut dual.  If we do not identify a feasibility cut, we pass the constraint generated to the optimality cut dual. Both constraint generation are implemented using a callback mechanism in function separate_mst_Benders_cut!. ","category":"page"},{"location":"optimization/#Benders-master-problem","page":"Optimization algorithms","title":"Benders master problem","text":"","category":"section"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"Let us denote by mathcalF and mathcalO_s the feasibility cuts and the optimality cuts for scenario s. This leads us to the Benders master problem","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    beginarrayrlll\n        min displaystylesum_e in Ec_e x_e + sum_s in S theta_s\n        mathrmst \n         sum_e in E x_e leq V - 1  textInitial constraint not mandatory \n             nu + sum_emu_ex_e leq 0  textfor all munu in mathcalF\n         theta_s geq nu_s + sum_emu_esx_e - sum_sd_esx_es   textfor all  s in S and (munu) in mathcalO_s \n         x in 01 \n    endarray","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"Again, we implement the separation of the feasibility and optimality cuts using a callback mechanism in two_stage_spanning_tree_benders.","category":"page"},{"location":"optimization/#Lagrangian-relaxation","page":"Optimization algorithms","title":"Lagrangian relaxation","text":"","category":"section"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"Let us introduce one copy of x per scenario. An equivalent formulation of the problem is","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"beginarrayll\nmin  displaystyle sum_ein Ec_e x_e + sum_e in E sum_s in Sd_esy_es \nmathrmst  mathbfx_s + mathbfy_s in mathcalP quadquad textfor all s in S  \n x_es = x_e quad quad quad textfor all e in E and s in S\nendarray","category":"page"},{"location":"optimization/#Lagrangian-dual-function-and-its-gradient","page":"Optimization algorithms","title":"Lagrangian dual function and its gradient","text":"","category":"section"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"Let us relax the constraint x_es = x_e. We denote by theta_es the associated Lagrange multiplier.","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"The Lagrangian dual problem becomes","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"beginarrayrlrlrl\nmax_thetamathcalG(theta)= \nmin_x sum_e in E(c_e + frac1Ssum_s in S theta_es)x_e +  frac1Ssum_s in Smin_mathbfx_smathbfy_s  sum_e in Ed_esy_es - theta_esx_es\nmathrmst 0 leq mathbfx leq M \n mathrmst  mathbfx_s + mathbfy_s in mathcalP quadquad textfor all s in S  \nendarray","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"where M is a large constant.  In theory, we would take M=+infty, but taking a finite M leads to more ingformative gradients.","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"Solving the first stage subproblem amounts to checking the sign of c_e + sum_s in S theta_es, while the optimal solution of the second stage problem can be computed using Kruskal's algorithm.","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"We have","category":"page"},{"location":"optimization/","page":"Optimization algorithms","title":"Optimization algorithms","text":"    (nabla mathcalG(theta))_es= frac1S (x_e - x_es)","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"EditURL = \"https://github.com/axelparmentier/MaximumWeightTwoStageSpanningTree.jl/blob/main/scripts/run_paper_experiments.jl\"","category":"page"},{"location":"run_paper_experiments/#*Learning-structured-approximations-of-combinatorial-optimization-problems*-paper-experiments","page":"Experiments","title":"Learning structured approximations of combinatorial optimization problems - paper experiments","text":"","category":"section"},{"location":"run_paper_experiments/#Load-packages","page":"Experiments","title":"Load packages","text":"","category":"section"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"using UnicodePlots\nusing MaximumWeightTwoStageSpanningTree\nusing Graphs","category":"page"},{"location":"run_paper_experiments/#Build-training-and-test-set","page":"Experiments","title":"Build training and test set","text":"","category":"section"},{"location":"run_paper_experiments/#Choose-dataset-parameters","page":"Experiments","title":"Choose dataset parameters","text":"","category":"section"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"This is the only block you should modify Set only_small to false and smaller_datasets to false to run the experiments in the paper. Beware, it takes several days to run.","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"only_small = true # if true, only small instances are considered\nsmaller_datasets = true # if true, fewer instances are considered computation takes roughly one hour, if false several days\nnormalized = true","category":"page"},{"location":"run_paper_experiments/#Build-datasets","page":"Experiments","title":"Build datasets","text":"","category":"section"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"@time training_datasets, validation_datasets, test_datasets = build_or_load_spanning_tree_CO_layer_datasets(;\n    parallel=false, # Use true only if solutions have already been computed in folder data, otherwise it may bug due to the MILP solver\n    only_small=only_small,\n    only_lagrangian=false,\n    normalized=normalized,\n    negative_weights=true,\n    smaller_datasets=smaller_datasets,\n);\n\nmodels = Dict()","category":"page"},{"location":"run_paper_experiments/#Train-models","page":"Experiments","title":"Train models","text":"","category":"section"},{"location":"run_paper_experiments/#Supervised-learning-with-Fenchel-Young-Losses-(FYL)","page":"Experiments","title":"Supervised learning with Fenchel Young Losses (FYL)","text":"","category":"section"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"for (dataset_name, dataset) in training_datasets\n    println(\"training with FYL on \", dataset_name)\n    model, training_time, losses = train_save_or_load_FYL_model!(;\n        nb_samples=20, train_data=dataset, train_data_name=dataset_name, nb_epochs=200\n    )\n    model_name = \"fyl_\" * dataset_name * \"_iter200_perttrue_intpert1_nbpert20\"\n    models[model_name] = Dict(\n        \"model\" => model,\n        \"learning_algorithm\" => \"fyl\",\n        \"train_data_name\" => dataset_name,\n        \"training_time\" => training_time,\n        \"pert\" => true,\n        \"intpert\" => 1.0,\n        \"nbpert\" => 20,\n        \"losses\" => losses,\n    )\n    println(lineplot(losses))\nend","category":"page"},{"location":"run_paper_experiments/#Learning-by-experience-with-global-derivative-free-algorithm","page":"Experiments","title":"Learning by experience with global derivative free algorithm","text":"","category":"section"},{"location":"run_paper_experiments/#Non-perturbed","page":"Experiments","title":"Non perturbed","text":"","category":"section"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"for (dataset_name, dataset) in training_datasets\n    train_bbl_model_and_add_to_dict!(\n        models; train_data_name=dataset_name, train_data=dataset, nb_DIRECT_iterations=1000\n    )\nend","category":"page"},{"location":"run_paper_experiments/#Perturbed","page":"Experiments","title":"Perturbed","text":"","category":"section"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"intensities = [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3]\n\nfor intensity in intensities\n    for (dataset_name, dataset) in training_datasets\n        @info \"bbl on \" * dataset_name * \" with intensity \" * string(intensity)\n        train_bbl_model_and_add_to_dict!(\n            models;\n            train_data_name=dataset_name,\n            train_data=dataset,\n            nb_DIRECT_iterations=1000,\n            perturbed=true,\n            perturbation_intensity=intensity,\n            nb_perturbations=20,\n        )\n    end\nend","category":"page"},{"location":"run_paper_experiments/#Add-model-corresponding-to-the-approximation-algorithm","page":"Experiments","title":"Add model corresponding to the approximation algorithm","text":"","category":"section"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"models[\"approx\"] = Dict(\n    \"model\" => MaximumWeightTwoStageSpanningTree.approx_algorithm_model(),\n    \"learning_algorithm\" => \"approx\",\n    \"train_data_name\" => \"--\",\n    \"training_time\" => \"--\",\n    \"pert\" => false,\n    \"intpert\" => 0,\n    \"nbpert\" => 0,\n)","category":"page"},{"location":"run_paper_experiments/#Evaluate-model-performances-on-validation-and-test-sets","page":"Experiments","title":"Evaluate model performances on validation and test sets","text":"","category":"section"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"recompute_results = false # put to true to force results recompute (needed if content of validation or test sets changed)\nresults_folder = \"results\"\nmkpath(results_folder)\nval_and_test_sets = merge(validation_datasets, test_datasets)\nresults = test_or_load_models_on_datasets(\n    models=models,\n    datasets=val_and_test_sets,\n    results_folder=results_folder,\n    recompute_results=recompute_results\n)","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"Add model corresponding to ub","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"models[\"ub\"] = Dict(\n    \"learning_algorithm\" => \"UB\",\n    \"train_data_name\" => \"--\",\n    \"training_time\" => \"--\",\n    \"pert\" => false,\n    \"intpert\" => 0,\n    \"nbpert\" => 0,\n)","category":"page"},{"location":"run_paper_experiments/#Build-hyperparameters-choice-table","page":"Experiments","title":"Build hyperparameters choice table","text":"","category":"section"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"using Printf","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"Function to compute averages on datasets","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"function average_and_worst_on_dataset(dataset_results, f)\n    model_names = collect(keys(dataset_results[1][3]))\n    averages = Dict(zip(model_names, zeros(length(model_names))))\n    worsts = Dict(zip(model_names, -Inf * ones(length(model_names))))\n    for (_, lb, ubs) in dataset_results\n        for (model_name, ub) in ubs\n            f_val = f(lb, ub)\n            averages[model_name] += f_val\n            worsts[model_name] = max(worsts[model_name], f_val)\n        end\n    end\n    l = length(dataset_results)\n    map!(x -> x / l, values(averages))\n    return (averages, worsts)\nend","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"Hyperparameter tunning table","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"tables_folder = \"tables\"\nmkpath(tables_folder)\n\nbegin\n    io_hyperparams = open(joinpath(tables_folder, \"hyperparameters_neg.tex\"), \"w\")\n    for (name, _) in validation_datasets\n        println(\"Gap on \", name)\n        averages, worsts = average_and_worst_on_dataset(\n            results[name], (lb, ub) -> (ub - lb) / -lb\n        )\n        for model in sort(collect(keys(averages)))\n            train_data_name = models[model][\"train_data_name\"]\n            learning_algorithm = models[model][\"learning_algorithm\"]\n            intpert = models[model][\"pert\"] ? models[model][\"intpert\"] : 0.0\n            gap_percent = 100 * averages[model]\n            @printf(\n                \"%s & %s & %.1e & %.1f\\\\%% \\\\\\\\\\n\",\n                train_data_name,\n                learning_algorithm,\n                intpert,\n                gap_percent\n            )\n            @printf(\n                io_hyperparams,\n                \"%s & %s & %.1e & %.1f\\\\%% \\\\\\\\\\n\",\n                train_data_name,\n                learning_algorithm,\n                intpert,\n                gap_percent\n            )\n        end\n    end\n    close(io_hyperparams)\nend\nmodel_names = collect(keys(results))","category":"page"},{"location":"run_paper_experiments/#Build-Figure-evaluating-the-performance-of-the-model","page":"Experiments","title":"Build Figure evaluating the performance of the model","text":"","category":"section"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"Following the results of the hyper-parameter tuning model, we use 1e-3","category":"page"},{"location":"run_paper_experiments/#Starts-by-choosing-the-datasets-and-models-used-for-the-figure-in-accordance-with-initial-dataset-selection","page":"Experiments","title":"Starts by choosing the datasets and models used for the figure in accordance with initial dataset selection","text":"","category":"section"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"performance_dataset_name = \"large_lagrangian_test_data_normtrue_negtrue\"\nperformance_bbl_model_name = \"bbl_large_lagrangian_train_data_normtrue_negtrue_iter1000_perttrue_intpert0.001_nbpert20\"\nperformance_fyl_model_name = \"fyl_large_lagrangian_train_data_normtrue_negtrue_iter200_perttrue_intpert1_nbpert20\"\nx_nb_vertices = [x^2 for x in 10:10:60]\nif smaller_datasets\n    x_nb_vertices = [x^2 for x in 10:10:20]\n    performance_dataset_name = \"large_lagrangian_test_data_normtrue_negtrue_smaller\"\n    performance_bbl_model_name = \"bbl_large_lagrangian_train_data_normtrue_negtrue_smaller_iter1000_perttrue_intpert0.001_nbpert20\"\n    performance_fyl_model_name = \"fyl_large_lagrangian_train_data_normtrue_negtrue_smaller_iter200_perttrue_intpert1_nbpert20\"\nend\nif only_small\n    if smaller_datasets\n        performance_dataset_name = \"small_lagrangian_test_data_normtrue_negtrue_smaller\"\n        performance_bbl_model_name = \"bbl_small_benders_train_data_normtrue_negtrue_smaller_iter1000_perttrue_intpert0.001_nbpert20\"\n        performance_fyl_model_name = \"fyl_small_benders_train_data_normtrue_negtrue_smaller_iter200_perttrue_intpert1_nbpert20\"\n        \"ub\"\n        x_nb_vertices = [x^2 for x in 4:5]\n    else\n        performance_dataset_name = \"small_lagrangian_test_data_normtrue_negtrue\"\n        performance_bbl_model_name = \"bbl_small_benders_train_data_normtrue_negtrue_iter1000_perttrue_intpert0.001_nbpert20\"\n        performance_fyl_model_name = \"fyl_small_benders_train_data_normtrue_negtrue_iter200_perttrue_intpert1_nbpert20\"\n        \"ub\"\n        x_nb_vertices = [x^2 for x in 4:6]\n    end\nend","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"Performance of the approximation algorithm","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"average_and_worst_on_dataset(\n    results[performance_dataset_name], (lb, ub) -> (ub - lb) / -lb\n)[2][\"approx\"]\n\nfunction conditional_average_and_worst_for_model(\n    dataset_results, statistic, model_name, condition=instance -> true\n)\n    count = 0\n    average = 0.0\n    worst = -Inf\n    for (instance, lb, ubs) in dataset_results\n        if condition(instance)\n            stat_val = statistic(lb, ubs[model_name])\n            count += 1\n            average += stat_val\n            worst = max(worst, stat_val)\n        end\n    end\n    average /= count\n    return (average, worst)\nend","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"Compute plot data","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"pipelines_average_worst = [\n    conditional_average_and_worst_for_model(\n        results[performance_dataset_name],\n        (lb, ub) -> (ub - lb) / -lb,\n        performance_bbl_model_name,\n        instance -> nv(instance.g) == nb_vert,\n    ) for nb_vert in x_nb_vertices\n]\ny_pipeline_average = [y for (y, _) in pipelines_average_worst]\ny_pipeline_worst = [y for (_, y) in pipelines_average_worst]\n\nfyl_average_worst = [\n    conditional_average_and_worst_for_model(\n        results[performance_dataset_name],\n        (lb, ub) -> (ub - lb) / -lb,\n        performance_fyl_model_name,\n        instance -> nv(instance.g) == nb_vert,\n    ) for nb_vert in x_nb_vertices\n]\ny_fyl_average = [y for (y, _) in fyl_average_worst]\ny_fyl_worst = [y for (_, y) in fyl_average_worst]\n\napprox_average_worst = [\n    conditional_average_and_worst_for_model(\n        results[performance_dataset_name],\n        (lb, ub) -> (ub - lb) / -lb,\n        \"approx\",\n        instance -> nv(instance.g) == nb_vert,\n    ) for nb_vert in x_nb_vertices\n]\ny_approx_average = [y for (y, _) in approx_average_worst]\ny_approx_worst = [y for (_, y) in approx_average_worst]\n\nlh_average_worst = [\n    conditional_average_and_worst_for_model(\n        results[performance_dataset_name],\n        (lb, ub) -> (ub - lb) / -lb,\n        \"ub\",\n        instance -> nv(instance.g) == nb_vert,\n    ) for nb_vert in x_nb_vertices\n]\ny_lh_average = [y for (y, _) in lh_average_worst]\ny_lh_worst = [y for (_, y) in lh_average_worst]","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"Plot. Result in folder \"figures/gaptolag_bound.pdf\"","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"using CairoMakie\nCairoMakie.activate!()\nfigure_path = \"figures\"\nmkpath(figure_path)\n\nbegin\n    fig = Figure()\n    ax = Axis(\n        fig[1, 1];\n        xlabel=\"|V|\",\n        ylabel=\"Gap to Lagrangian Bound (%)\",\n        limits=(0, maximum(x_nb_vertices), 0, 6.8),\n    )\n    lines!(\n        ax,\n        x_nb_vertices,\n        100 * y_pipeline_average;\n        label=\"Pipeline (Regret) average gap\",\n        linestyle=:dashdot,\n    )\n    lines!(\n        ax,\n        x_nb_vertices,\n        100 * y_pipeline_worst;\n        label=\"Pipeline (Regret) worst gap\",\n        linestyle=:dashdot,\n    )\n    lines!(\n        ax,\n        x_nb_vertices,\n        100 * y_fyl_average;\n        label=\"Pipeline (FYL) average gap\",\n        linestyle=:dot,\n    )\n    lines!(\n        ax,\n        x_nb_vertices,\n        100 * y_fyl_worst;\n        label=\"Pipeline (FYL) worst gap\",\n        linestyle=:dot,\n    )\n    lines!(ax, x_nb_vertices, 100 * y_lh_average; label=\"Lagrangian heuristic average gap\")\n    lines!(ax, x_nb_vertices, 100 * y_lh_worst; label=\"Lagrangian heuristic worst gap\")\n    lines!(ax, x_nb_vertices, 100 * y_approx_average; label=\"Approx algorithm average gap\")\n    lines!(ax, x_nb_vertices, 100 * y_approx_worst; label=\"Approx algorithm worst gap\")\n    axislegend(ax)\n    current_figure()\n    save(joinpath(figure_path, \"gap_to_lag_bound.pdf\"), current_figure())\nend","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"","category":"page"},{"location":"run_paper_experiments/","page":"Experiments","title":"Experiments","text":"This page was generated using Literate.jl.","category":"page"},{"location":"problem/#Problem-statement","page":"Problem statement","title":"Problem statement","text":"","category":"section"},{"location":"problem/","page":"Problem statement","title":"Problem statement","text":"Let G = (VE) be an undirected graph, and S be a set of scenario.  For each edge e in E, we suppose to have a first stage cost c_e in mathbbR. And for each e in E and s in S, we suppose to have a second stage cost d_es.","category":"page"},{"location":"problem/","page":"Problem statement","title":"Problem statement","text":"Let mathcalP be the spanning tree polytope in mathbbR^E. The two stage spanning tree problem can be formulated as follows,","category":"page"},{"location":"problem/","page":"Problem statement","title":"Problem statement","text":"beginarrayll\nmin  displaystyle sum_ein Ec_e x_e + dfrac1Ssum_e in E sum_s in Sd_esy_es \nmathrmst  mathbfx + mathbfy_s in mathcalP quadquad textfor all s in S \nendarray","category":"page"},{"location":"problem/","page":"Problem statement","title":"Problem statement","text":"where x_e is a binary variable indicating if e is in the first stage solution, y_es is a binary variable indicating if e is in the second stage solution for scenario s, mathbfx = (x_e)_e in E, and mathbfy_s = (y_es)_e in E.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = MaximumWeightTwoStageSpanningTree","category":"page"},{"location":"#MaximumWeightTwoStageSpanningTree.jl","page":"Home","title":"MaximumWeightTwoStageSpanningTree.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for MaximumWeightTwoStageSpanningTree.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package enables to reproduce the numerical experiments in Learning structured approximations of operations research problems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Further details on the problem considered are available here.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Details on the Lagrangian relaxation and the Lagrangian heuristic algorithms used in the paper experiments are available here.","category":"page"},{"location":"#Numerical-experiments-in-the-results.","page":"Home","title":"Numerical experiments in the results.","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A notebook with the numerical experiments run in the paper is available here.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In order to reproduce the paper experiments, open a julia repl in the package folder, and run the following code.","category":"page"},{"location":"","page":"Home","title":"Home","text":"    using Pkg\n    Pkg.activate(\".\")\n    Pkg.activate(\"./scripts\")\n    Pkg.rm(\"MaximumWeightTwoStageSpanningTree\") # Manifest.toml is not pushed, it would take the registry version, which does not exist\n    Pkg.develop(path=\".\") # Takes instead the local version\n    Pkg.instantiate()\n    include(\"scripts/run_paper_experiments.jl\")","category":"page"}]
}
